#' Gather files
#'
#' Recursively find peak/picard files stored within subdirectories and import
#' them as a list of \link[GenomicRanges]{GRanges} objects.
#'
#' @param dir Directory to search within.
#' @param type File type to search for. Options include:
#' \itemize{
#' \item{"<pattern>"}{Finds files matching an arbitrary regex pattern
#' specified by user.}
#' \item{"peaks.stringent"}{Finds files ending in "*.peaks.bed.stringent.bed$"}
#' \item{"peaks.consensus"}{Finds files ending in "*.peaks.bed.stringent.bed$"}
#' \item{"peaks.consensus.filtered"}{
#' Finds files ending in"*.consensus.peaks.filtered.awk.bed$"}
#' \item{"picard"}{Finds files ending in
#' "*.target.markdup.MarkDuplicates.metrics.txt$"}
#' }
#' @param nfcore_cutandrun Whether the files were generated by the
#' \href{https://nf-co.re/cutandrun}{nf-core/cutandrun} Nextflow pipeline.
#'  If \code{TRUE}, can use the standardised folder structure to
#'  automatically generate more descriptive file names with sample IDs.
#' @param mc.cores Number of cores to parallelise importing
#'
#' @returns A named list of \link[GenomicRanges]{GRanges} objects.
#'
#' @export
#' @importFrom dplyr %>%
#' @importFrom stringr str_split
#' @importFrom GenomicRanges makeGRangesFromDataFrame
#' @examples
#' #### Make example files ####
#' save_paths <- EpiCompare::write_example_peaks()
#' dir <- unique(dirname(save_paths))
#'
#' #### Gather/import files ####
#' peaks <- EpiCompare::gather_files(dir=dir, type="*.narrowPeaks.bed$")
gather_files <- function(dir,
                         type = "peaks.consensus.filtered",
                         nfcore_cutandrun = FALSE,
                         mc.cores = 1){
  requireNamespace("data.table")
  requireNamespace("BiocParallel")
  type_key <- c(
    "peaks.stringent"="*.peaks.bed.stringent.bed$",
    "peaks.consensus"="*.consensus.peaks.bed$",
    "peaks.consensus.filtered"="*.consensus.peaks.filtered.awk.bed$",
    "picard"= "*.target.markdup.MarkDuplicates.metrics.txt$"
  )
  pattern <- if(type %in% names(type_key)) type_key[tolower(type)] else type
  if(is.na(pattern)){
    stop("type must be one of:\n",
         paste("-",names(type_key), collapse = "\n"))
  }
  message("Searching for ",type," files...")
  paths <- list.files(path = dir,
                      pattern = paste(unname(pattern), collapse = "|"),
                      recursive = TRUE,
                      full.names = TRUE)
  #### Report files found ####
  if(length(paths)==0) stop(length(paths)," matching files identified.")
  message(length(paths)," matching files identified.")
  #### Construct names ####
  names <- gather_files_names(paths=paths,
                              type=type,
                              nfcore_cutandrun=nfcore_cutandrun)
  #### Import files ####
  message("Importing files.")
  #set number of workers - used for bpapply below
  BiocParallel::register(BiocParallel::MulticoreParam(workers=mc.cores))
  files <- BiocParallel::bplapply(paths, function(x){
    message_parallel(x,"\n")
    if(startsWith(type,"peaks")){
      dat <- ChIPseeker::readPeakFile(x, as = "GRanges")
    } else if(type=="picard"){
      dat <- data.table::fread(x,
                               skip = "LIBRARY",
                               fill = TRUE,
                               nrows = 1)
    } else if(grepl("narrowPeak",x)){
      dat <- import_narrowPeak(path = x)
    } else {
      dat <- data.table::fread(x)
    }
    #### Ensure GRanges format ####
    if(!methods::is(dat,"GRanges")) {
      ## Try to convert to GRanges, but if it fails,
      ## just return the data.table
      dat <- tryCatch({
        GenomicRanges::makeGRangesFromDataFrame(
          df = dat,
          keep.extra.columns = TRUE)
      }, error = function(e) dat)
    }
    return(dat)
  }) %>% `names<-`(names)
  return(files)
}

